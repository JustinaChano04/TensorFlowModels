{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SlimYOLOv3 in Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0ADJq0MrcNO"
      },
      "source": [
        "# SlimYOLOv3 in Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wroONlMJNC9z"
      },
      "source": [
        "This is a Google Colaboratory notebook file to demonstrate channel pruning and the inference using a TensorFlow implementation of SlimYOLOv3 on the VisDrone2018-DET dataset.\n",
        "\n",
        "First, we will mount Google Drive to access the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7W-wftMCVoP"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive/SlimYOLOv3-tf/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMTwT0W7Nevo"
      },
      "source": [
        "Next the requirements for the project will be installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDu3iG1VNePK"
      },
      "source": [
        "!pip install -r requirements.txt\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import keras_flops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNmfgSUiEGTH"
      },
      "source": [
        "## Demonstration of SlimYOLOv3 after Pruning and Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMJ5xYsOA-F4"
      },
      "source": [
        "Now you are ready to try out the model that I pruned and trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbUgtyT-EFtA"
      },
      "source": [
        "from IPython.display import display, Image\n",
        "from analysis.predict_image import image_processor\n",
        "import tensorflow as tf\n",
        "\n",
        "# https://stackoverflow.com/a/37061069\n",
        "import PIL.Image\n",
        "from io import BytesIO\n",
        "import IPython.display\n",
        "import numpy as np\n",
        "def showarray(a, fmt='png'):\n",
        "    a = np.uint8(a)\n",
        "    f = BytesIO()\n",
        "    PIL.Image.fromarray(a).save(f, fmt)\n",
        "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
        "\n",
        "model = tf.keras.models.load_model('checkpoints/1-finetuned')\n",
        "image_processor(model, 'subset/0000193_00000_d_0000103.jpg', showarray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NegHGouZBEcb"
      },
      "source": [
        "The above image is an example of the large bias towards cars in the detection. This bias was caused by a dataset bias. Because the VisDrone dataset consists of street images in China, there are many more cars in the images than pedestrians or motorcyclists. Feel free to change the model specified or the image. Getting accurate measure of the latency in Colab can be difficult."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDzMcqCANfqo"
      },
      "source": [
        "## Example of Channel Pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_qnSmj12D-S"
      },
      "source": [
        "The core portion of my implementation is the channel pruning utility for TensorFlow. The syntax is as shown below:\n",
        "\n",
        "```{python3}\n",
        "prune(input_file, layer_ratio, total_ratio, output_file)\n",
        "```\n",
        "\n",
        "The pruning function requires two pruning hyperparameters: the layer ratio and the total ratio. First, a threshold for weights that are considered insigificant is obtained from the total ratio. For example, if the total ratio is 0.5, then the bottom 50% of channel weights are considered insignificant to the functioning of the model and can be removed. They are only removed if the the layer ratio is met. For example, if the layer ratio is 0.1, then channels are not removed from a layer until 10% of the channels in a layer are unimportant. If either threshold is not met, a channel is not pruned. Below is the general syntax of calling this function.\n",
        "\n",
        "```{python3}\n",
        "from training.prune import prune\n",
        "prune('sparse', 0.1, 0.5, 'pruned')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_2a5roBNcLE"
      },
      "source": [
        "from training.prune import prune\n",
        "model = tf.keras.models.load_model('checkpoints/1-sparse')\n",
        "flops = keras_flops.get_flops(model, batch_size=1)\n",
        "print(f\"Before Pruning FLOPS: {flops / 10 ** 9:.03} G\")\n",
        "new_model = prune('checkpoints/1-sparse', 0.1, 0.5, 'checkpoints/1-pruned')\n",
        "model.summary()\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adNaq_kX5bI7"
      },
      "source": [
        "There is a lot of output from this cell, but the key results are that the pruning process reduced the number of operations in the model from 152 billion floating point operations per second (FLOPS) to just 69.7 FLOPS. The number of parameters in the model also reduced from 63.9 million to just 29.1 million."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7LKgkRnsnin"
      },
      "source": [
        "# Reproduction of the Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4I8SBg_1tHw"
      },
      "source": [
        "This cell is used to calculate all of the numbers in Table 1 in the paper. Unfortunately, TensorFlow 2 removed the field that allows direct access to the number of trainable parameters, so the \"Trainable Parameters\" line on the summary will give the numbers for this for each model. Latency is very unpredictable on Colab because it is a shared system. Running late at night on a user that didn't have too much Colab use in the recent past seem to have the most consistant results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE4OEFQWsYsb"
      },
      "source": [
        "import timeit\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import keras_flops\n",
        "\n",
        "dummy = tf.ones((1, 608, 608, 3))\n",
        "for path in ['checkpoints/0-unpruned', 'checkpoints/1-sparse', 'checkpoints/1-pruned', 'checkpoints/1-finetuned']:\n",
        "  model = tf.keras.models.load_model(path)\n",
        "  flops = keras_flops.get_flops(model, batch_size=1)\n",
        "  model.summary() # for number of (trainable) parameters\n",
        "  print(f\"{path} FLOPS: {flops / 10 ** 9:.03} G\")\n",
        "  print(f'{path} Latency: {timeit.timeit(\"model(dummy)\", globals=vars(), number=5)} s')\n",
        "  del model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}